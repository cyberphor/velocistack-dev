services:
  velociraptor: 
    profiles: [ "velocistack", "velociraptor" ]
    build: velociraptor
    image: velociraptor:dev
    container_name: velociraptor
    hostname: velociraptor
    env_file: .env
    volumes:
      - velociraptor_data:/opt/velociraptor/
      - velociraptor_api:/api/
    ports:
      - "8000:8000" # server-to-client communication
      - "8001:8001" # gRPC server (handles API request)
      - "8003:8003" # Prometheus monitoring server
      - "8443:8443" # web console
    networks: 
      velocistack:
  # cyber-chef: 
  #   profiles: [ "velocistack", "cyber-chef" ]
  #   build: cyber-chef
  #   image: cyber-chef:dev
  #   container_name: cyber-chef
  #   hostname: cyber-chef
  #   ports:
  #     - "8443:8443"
  postgres: # database
    profiles: [ "velocistack", "intelowl", "iris", "postgres" ]
    build: postgres
    image: postgres:dev
    container_name: postgres
    hostname: postgres
    env_file: .env
    volumes:
      - postgres:/var/lib/postgresql/data/
    ports:
      - "5432:5432"
    networks: 
      velocistack:
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U $POSTGRES_USER -d $POSTGRES_DB_INTELOWL" ]
      start_period: 10s
      interval: 10s
      timeout: 3s
      retries: 3
  rabbitmq: # message broker between (Nginx > uWSGI > Intel Owl) and Celery
    profiles: [ "velocistack", "intelowl" ]
    build: rabbitmq
    image: rabbitmq:dev
    container_name: rabbitmq
    hostname: rabbitmq
    env_file: .env
    ports:
      - "5672:5672"
      - "15672:15672"
    networks: 
      velocistack:
    depends_on:
      postgres:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "rabbitmq-diagnostics ping -q"]
      start_period: 10s
      interval: 10s
      timeout: 3s
      retries: 3
  # celery-beat: # schedules tasks for Intel Owl; sends results to Postgres
  #   profiles: [ "velocistack", "intelowl" ]
  #   build: celery-beat
  #   image: celery-beat:dev
  #   container_name: celery-beat
  #   hostname: celery-beat
  #   env_file: .env
  #   volumes:
  #     - logs:/var/log/intel_owl/
  #     - shared:/opt/deploy/files_required
  #   networks: 
  #     velocistack:
  #   depends_on:
  #     postgres:
  #       condition: service_healthy
  #     rabbitmq:
  #       condition: service_healthy
  # healthcheck:
  #   test: ["CMD-SHELL", "ps aux | grep -i '[c]elery"]
  #   start_period: 10s
  #   interval: 10s
  #   timeout: 3s
  #   retries: 3
  # celery-worker: # off-loads tasks for Intel Owl; sends results to Postgres
  #   profiles: [ "velocistack", "intelowl" ]
  #   build: celery-worker
  #   image: celery-worker:dev
  #   container_name: celery-worker
  #   hostname: celery-worker
  #   env_file: .env
  #   volumes:
  #     - logs:/var/log/intel_owl/
  #     - shared:/opt/deploy/files_required
  #   networks: 
  #     velocistack:
  #   depends_on:
  #     postgres:
  #       condition: service_healthy
  #     rabbitmq:
  #       condition: service_healthy
  # healthcheck:
  #   test: ["CMD-SHELL", "ps aux | grep -i '[c]elery"]
  #   start_period: 10s
  #   interval: 10s
  #   timeout: 3s
  #   retries: 3
  intelowl: # Web Server Gateway Interface between Nginx and Intel Owl (a Python/Django-based app)
    profiles: [ "velocistack", "intelowl" ]
    build: intelowl
    image: intelowl:dev
    container_name: intelowl
    hostname: intelowl
    env_file: .env
    volumes:
      - logs:/var/log/intel_owl/
      - web:/opt/deploy/intel_owl/static/
    ports:
      - "80"
    networks: 
      velocistack:
    depends_on:
      postgres:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
      # celery-beat:
      #   condition: service_started
      # celery-worker:
      #   condition: service_started
  iris:
    profiles: [ "velocistack", "iris" ]
    build: iris
    image: iris:dev
    container_name: iris
    hostname: iris
    env_file: .env
    ports:
     - "80"
    networks: 
      velocistack:
    depends_on:
      postgres:
        condition: service_healthy
  nginx: # front-end web server
    profiles: [ "velocistack", "intelowl", "iris" ]
    build: nginx
    image: nginx:dev
    container_name: nginx
    hostname: nginx
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./nginx/errors.conf:/etc/nginx/conf.d/errors.conf
      - ./nginx/locations.conf:/etc/nginx/conf.d/locations.conf
      - certs:/etc/nginx/ssl/
      - logs:/var/log/nginx/
    ports:
      - "80:80"
    networks: 
      velocistack:
    depends_on:
      - intelowl # upstream server needs to be up first for redirection
    # - iris
  elasticsearch:
    profiles: [ "velocistack", "elastic" ]
    build: elasticsearch
    image: elasticsearch:dev
    container_name: elasticsearch
    hostname: elasticsearch
    env_file: .env
    volumes:
      - ./elasticsearch/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml
      - certs:/usr/share/elasticsearch/config/certs/
    # - logs:/usr/share/elasticsearch/logs/
    ports:
      - "9200:9200"
    networks: 
      velocistack:
        ipv4_address: ${ES_IP}
    healthcheck:
      test: ["CMD-SHELL", "curl ${ES_HOST} --cacert ${ES_PUBLIC_KEY} -u ${ELASTIC_USERNAME}:${ELASTIC_PASSWORD}"]
      start_period: 30s
      interval: 5s
      retries: 3
  kibana:
    profiles: [ "velocistack", "elastic" ]
    build: kibana
    image: kibana:dev
    container_name: kibana
    hostname: kibana
    env_file: .env
    volumes:
      - certs:/usr/share/kibana/config/certs/
    # - logs:/usr/share/kibana/logs/
    ports:
      - "${KIBANA_PORT}:${KIBANA_PORT}"
    extra_hosts:
      - "elasticsearch:${ES_IP}"
    networks: 
      velocistack:
        ipv4_address: ${KIBANA_IP}
    depends_on:
      elasticsearch:
        condition: service_healthy
    healthcheck:
      test: [ "CMD-SHELL", "curl http://${KIBANA_IP}:${KIBANA_PORT} -I -s | grep -q 'HTTP/1.1 302 Found'", ]
  # cadvisor:
  #   profiles: [ "velocistack", "prometheus" ] 
  #   build: cadvisor
  #   image: cadvisor:dev 
  #   container_name: cadvisor
  #   hostname: cadvisor
  #   ports:
  #     - "8080:8080"
  #   networks: 
  #     velocistack:
  prometheus:
    profiles: [ "velocistack", "prometheus" ]
    build: prometheus
    image: prometheus:dev
    container_name: prometheus
    hostname: prometheus
    env_file: .env
    ports:
      - "9090:9090"
    networks: 
      velocistack:
    # depends_on:
    #   - cadvisor
  grafana:
    profiles: [ "velocistack", "grafana" ]
    build: grafana
    image: grafana:dev
    container_name: grafana
    hostname: grafana
    env_file: .env
    ports:
      - "3000:3000"
    networks: 
      velocistack:
  # zinc:
  #   profiles: [ "velocistack", "zinc" ]
  #   build: zinc
  #   image: zinc:dev
  #   container_name: zinc
  #   hostname: zinc
  #   env_file: .env
  #   networks: 
  #     velocistack:

volumes:
  certs:
    name: certs
  logs:
    name: logs
  postgres:
    name: postgres
  web: 
    name: web
  shared:
    name: shared
  velociraptor_data:
    name: velociraptor_data
  velociraptor_api:
    name: velociraptor_api

networks:
  velocistack:
    name: velocistack
    ipam: 
      config: 
        - subnet: ${SUBNET}